---
title: "A Case for Percentiles"
subtitle: ""
author: "D.E. Beaudette"
date: "`r Sys.Date()`"
output:
  tint::tintHtml: 
    self_contained: TRUE
    smart: yes
    keep_md: no
link-citations: yes
---

```{r setup, echo=FALSE, results='hide', warning=FALSE}
# setup
library(tint)
library(knitr)
opts_chunk$set(message=FALSE, warning=FALSE, background='#F7F7F7', fig.retina=2, dev='png', tidy=FALSE, verbose=FALSE, cache = FALSE)
options(width=100, stringsAsFactors=FALSE, cache=FALSE)
```




# Introduction

Nearly all statistical methods are based on the premise that meaningful descriptions of an underlying population can be derived from a [subset of the population, or  *sample*](https://en.wikipedia.org/wiki/Sampling_(statistics)). The efficiency of a sample is (mostly) dependent on three parameters: the shape of the population distribution, the size of the sample and the degree to which values in the population are related ([autocorrelation](https://en.wikipedia.org/wiki/Autocorrelation)). A population with a simple distribution, such as the [normal](https://en.wikipedia.org/wiki/Normal_distribution), can be characterized with a smaller sample than more complex distributions. The effect of sample size makes intuitive sense: more observations (e.g. *larger* sample) will give a better description of the population, regardless of distribution. Characterization of populations with a low degree of autocorrelation require relatively larger samples as compared to populations with a high degree of autocorrelation.


# The population and the sample

```{r echo=FALSE, fig.margin=TRUE, fig.width=6, fig.height=3, fig.cap='The normal distribution, with a mean of 12% and standard deviation of 2%. Vertical lines mark the mean +/- 1 standard deviation.'}
n.x <- seq(5, 18, by=0.1)
n.y <- dnorm(seq(5, 18, by=0.1), mean=12, sd=2)
par(mar=c(4.5,0,0,0))
plot(n.x, n.y, type='l', axes=FALSE, xlab='Clay Content (%)', ylab='')
axis(side=1, labels = 5:18, at=5:18)
abline(v=c(10, 12, 14), lty=3)
```

For the sake of demonstration, lets pretend that we know some details about the population of possible clay contents associated with all A horizons, within a given soil series: the distribution shape is approximately normal, has a mean of 12% and a standard deviation of 2%. We can simulate these conditions by drawing a large number (1,000) of samples from the normal distribution. Having "access" to the clay content population is analogous to collecting all pixels (e.g. slope values) that overlap with a collection of map unit polygons. Next, draw a small sample (5% of the observations) from the population. This is analogous to the approach used by the MU summary reports: selecting pixels at a constant sampling density of approximately 1-5 points per acre.





